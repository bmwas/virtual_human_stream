1、 Cuda11.3 Container Startup Process
1. Copy the Dockerfile to any disk directory and then execute the following command
docker build -t nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda .

docker images

2. Start container
Open image (regular mode - supports GPU usage)
docker run -i -t --gpus all nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda  /bin/bash


Open image (enhanced mode - supports using GPU, mapping directory, setting memory)
docker run -i -t -v /home/liguopu/:/guopu:rw --gpus all --shm-size 16G nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04  /bin/bash

Test environment (using port mapping to map services out)
docker run -i -td --name metehuman --gpus -p 8000:8000 all nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda  /bin/bash

Formally used (Port 8000 is a service port for external business, which can be added according to the situation)
docker run -it --rm -p 8886:8888 -p 8000:8000 --gpus all nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda
docker run -itd -p 8886:8888 -p 8000:8000 --gpus all nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda
docker run -itd --name metehuman -p 8886:8888 -p 8000:8000 --gpus all nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda

docker run --gpus '"device=vgpu,id=0"' -it --rm nvidia/cuda:11.0-base nvidia-smi

docker run -itd --name metehuman \
-p 8885:8888 -p 8001:8000 \
-e GRANT_SUDO=yes \
-e JUPYTER_ENABLE_LAB=yes \
--user root \
--gpus all \
nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda

3. View token
token=$(docker exec -it metehuman jupyter server list | grep -oP '(?<=token=)[a-zA-Z0-9]+')
echo $token

2、 Start default test image
docker pull m11007322/cuda11.3.0-cudnn8-devel-ubuntu20.04-jupyterlab
docker run -it \
    -d \
    --gpus all \
    -p 8887:8888 \
    -p 8001:8000 \
    --name metehuman2 \
    --user root \
    -e NB_USER="ubuntu" \
    -e CHOWN_HOME=yes \
    -e GRANT_SUDO=yes \
    -w "/home/${NB_USER}" \
    -v "$PWD":"/home/$USER/work" \
    m11007322/cuda11.3.0-cudnn8-devel-ubuntu20.04-jupyterlab

3、 Start the Jupter image test
docker run -itd --name test \
-p 8886:8888 -p 8000:8000 \
-e GRANT_SUDO=yes \
-e JUPYTER_ENABLE_LAB=yes \
--user root \
--gpus '"device=vgpu,id=0"' \
nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04-jupyter-conda

docker run -it --name test --network=host --dns 8.8.8.8 --dns 8.8.4.4 --rm ubuntu
docker run -it --gpus all  --network=host --rm  registry.cn-hangzhou.aliyuncs.com/lipku/nerfstream:v1.3

4、 View container IP
docker inspect bceda087524e | grep IPAddress

curl https://openai.api2d.net/v1/chat/completions \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer fk193752-RlcPi2mBQqPOU5u1F8SFkG2z0gtxD0HS' \
  -d '{
  "model": "gpt-3.5-turbo",
  "messages": [{"role": "user", "content": "Who are you ?"}]
}'